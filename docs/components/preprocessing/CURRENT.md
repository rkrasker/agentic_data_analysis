# Preprocessing

**Status:** Regex extraction + synthetic adapter updated for v4.1; component routing pending; ADR-010 schema refactoring implemented
**Last Updated:** 2026-01-29

## Purpose

Extract structured fields from raw manifest-style records using deterministic regex matching. Outputs a
universal, record-level `canonical.parquet` for downstream routing/LLM workflows, plus
synthetic-only metadata for analysis.

## Responsibilities

- **Field extraction:** Parse roster text into structured categories (units, orgs, roles, numeric/alpha identifiers)
- **Glossary-driven patterns:** Build regex alternations from term glossaries with stem/literal matching logic
- **Component signal identification:** Extract signals for routing decisions (router pending)
- **Schema adaptation:** Bridge synthetic generator output to extraction inputs and split canonical vs metadata

## Architecture

### Input/Output Contract

**Input:**
- `data/synthetic/raw.parquet` with `source_id`, `soldier_id`, `raw_text`
- `data/synthetic/synthetic_records.parquet` for synthetic-only metadata (if present)

**Output:**
- `data/synthetic/canonical.parquet` (record-level)
  - core columns: `source_id`, `soldier_id`, `raw_text`
  - extraction columns from regex engine
- `data/synthetic/synthetic_records.parquet` (copied through when present)
- `data/synthetic/inferred_difficulty.parquet`
  - `inferred_collision_position`, `inferred_complementarity_score`
  - `inferred_structural_resolvability`, `inferred_difficulty_tier`
  - `inferred_candidate_branches`, `inferred_level_confidences`, `inferred_eliminating_constraints`

**Notes:**
- `sources.parquet` is generated by the synthetic pipeline but is **not** processed in preprocessing.
- Synthetic-only columns are passed through unchanged; preprocessing does not validate or re-compute them.
- Difficulty computation in `src/preprocessing/difficulty/` outputs `inferred_*` columns (no ground-truth access).

### File Structure

```
src/preprocessing/
├── hierarchy/                        # Hierarchy analysis utilities
│   ├── __init__.py
│   └── structural_discriminators.py  # Extract discrimination rules from hierarchy
├── difficulty/                       # Difficulty computation (inferred, no ground truth)
│   ├── __init__.py
│   └── compute.py                    # Outputs inferred_* columns (ADR-010)
├── regex_preprocessing.py            # Core extraction engine (domain-agnostic)
├── glossary_generator.py             # Generates v4.1 Terraform Combine glossary
├── preprocessing_adapter.py          # Bridges synthetic raw.parquet to extraction
├── component_router.py               # Route records based on signals (pending)
└── id_resolver.py                    # Corr table application (pending)

config/glossaries/
└── synthetic_glossary.json           # Auto-generated glossary (v4.1)

config/hierarchies/
├── hierarchy_reference.json          # Branch definitions (human-authored)
└── structural_discriminators.json    # Derived discrimination rules (computed)
```

## Key Design Choices

### 1) Glossary-driven pattern generation
Terms from the glossary drive regex alternations:
- **Short terms** (≤ threshold): literal match with letter-boundary constraint
- **Long terms** (> threshold): stem match allowing suffix variations

### 2) Unicode-safe boundaries
Uses Unicode-safe boundaries instead of `\b` to handle punctuation, accents, and OCR noise.

### 3) Paired category extraction
Captures term-number and term-alpha pairs bidirectionally and normalizes to canonical `TERM:VALUE`.

### 4) Factorize-extract-broadcast optimization
Extract each unique `Name ¶ Notes` once and broadcast results for speed.

### 5) Graceful degradation
Failures return sentinel values per category; pipeline continues.

## Implementation

### regex_preprocessing.py
Domain-agnostic extraction engine. Glossary defines the vocabulary; logic unchanged.

### glossary_generator.py (v4.1)
Generates Terraform Combine vocabulary from config files.

**Source files:**
- `docs/components/synthetic_data_generation/synthetic_style_spec_v4.1.yaml`
- `config/hierarchies/hierarchy_reference.json`
- `config/synthetic/synthetic_vocabulary.json`

**Term types extracted:**
- **Organization Term:** Branch names (e.g., Colonial Administration/CA)
- **Unit Term:** Level names + named designators (e.g., Sector, Squadron, Kestrel)
- **Role Term:** Placeholder (empty list; ranks TBD)

**Rules:**
- Use only explicit abbreviations from config.
- Do **not** include collision designators (digits/letters) as glossary terms.

### preprocessing_adapter.py (v4.1)
Bridges synthetic `raw.parquet` to regex extraction and splits outputs.

**Routing:**
- `raw.parquet` → canonical (core + extraction)
- `synthetic_records.parquet` → copied when present
- unexpected columns → synthetic_records (with warning)

**Join key:** `(source_id, soldier_id, state_id)`

**Extraction config:**
- `alpha_letters`: A–F
- `alpha_tokens`: none
- `num_max_len`: 3 (avoid 4-digit years)

## Current Outputs

- `data/synthetic/raw.parquet` — v4.1 schema, ~200k records
- `data/synthetic/validation.parquet` — ground truth per state
- `data/synthetic/canonical.parquet` — record-level extraction output
- `data/synthetic/synthetic_metadata.parquet` — synthetic-only fields
- `data/synthetic/inferred_difficulty.parquet` — inferred difficulty metrics (pending ADR-010)

## Testing & Validation

- Glossary regeneration: `python3.11 -m src.preprocessing.glossary_generator`
- Adapter run: `python3.11 -m src.preprocessing.preprocessing_adapter --timing`
- Structural discriminators: `python3.11 -m src.preprocessing.hierarchy.structural_discriminators`
- Validate join integrity on `(source_id, soldier_id, state_id)`

## Related ADRs

- **ADR-008:** Preprocessing v4.1 update (schema routing decisions)
- **ADR-010:** Synthetic metadata separation (inferred_ prefix convention, schema refactoring)

## Changelog

### v2.2.0 (2026-01-29)
- Documented ADR-010 schema refactoring (pending implementation)
- Added difficulty/ submodule to file structure
- Added inferred_difficulty.parquet to outputs
- Difficulty computation outputs use `inferred_*` prefix (no ground-truth access)

### v2.1.0 (2026-01-28)
- Added `hierarchy/` submodule with `structural_discriminators.py`
- Extracts level name, designator, and depth discriminators from hierarchy
- Generates `structural_discriminators.json` for difficulty model and resolver Phase 5

### v2.0.0 (2026-01-26)
- Updated glossary generator to Terraform Combine v4.1
- Updated adapter schema routing (state_id canonical, completeness fields to metadata)
- Explicit three-column join key for metadata
- Role terms placeholder documented

### v1.1.0 (2026-01-14)
- Added `glossary_generator.py` and `preprocessing_adapter.py`
- Added digit sequence extraction for slash/dash notation
- Initial synthetic glossary generation

### v1.0.0 (2026-01-12)
- Initial `regex_preprocessing.py` implementation
- Factorize-extract-broadcast optimization
- Unicode-safe boundaries, paired category extraction
