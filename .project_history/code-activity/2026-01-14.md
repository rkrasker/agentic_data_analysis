# Code Activity Log: 2026-01-14

**Session:** Claude Code (Opus 4.5)
**Focus:** Preprocessing pipeline - bridging synthetic data to regex extraction

---

## Summary

Connected the synthetic data generator output to the regex extraction pipeline via a glossary generator and preprocessing adapter. Added new `Digit_Sequences` extraction for slash/dash notation.

---

## Files Created

| File | Purpose |
|------|---------|
| `src/preprocessing/glossary_generator.py` | Build-time script to generate glossary from synthetic configs |
| `src/preprocessing/preprocessing_adapter.py` | Bridge synthetic `raw.parquet` to regex extraction |
| `config/glossaries/synthetic_glossary.json` | Auto-generated glossary (56 terms) |
| `data/synthetic/canonical.parquet` | Preprocessed output with 25 extraction columns |

## Files Modified

| File | Changes |
|------|---------|
| `src/preprocessing/regex_preprocessing.py` | Added `Digit_Sequences` pattern; fixed pandas 2.x compatibility |
| `docs/components/preprocessing/CURRENT.md` | Added glossary generator, adapter docs; changelog v1.1.0 |
| `docs/architecture/CURRENT.md` | Added status table, updated pipeline diagram |
| `README.md` | Updated current status, added Quick Commands |
| `instructions/active/README.md` | Added recently completed, suggested next |
| `instructions/completed/README.md` | Added completed instructions index |

---

## Implementation Details

### 1. Glossary Generator (`glossary_generator.py`)

Extracts terms from three synthetic config files:
- `synthetic_style_spec_v3.yaml` → ranks, unit labels
- `hierarchy_reference.json` → service branches
- `synthetic_vocabulary.json` → admin codes

**Output:** 56 terms (22 org, 20 unit, 14 role)

```bash
python3.11 -m src.preprocessing.glossary_generator
```

### 2. Preprocessing Adapter (`preprocessing_adapter.py`)

Bridges synthetic output to regex extraction:
1. Loads `raw.parquet` (synthetic output)
2. Adapts schema: `raw_text` → `Name` column
3. Loads generated glossary
4. Runs `extract_roster_fields()`
5. Saves `canonical.parquet`

```bash
python3.11 -m src.preprocessing.preprocessing_adapter --timing
```

### 3. Digit_Sequences Extraction

New regex pattern for slash/dash separated digit sequences:
- Pattern: `\d{1,3}(?:st|nd|rd|th)?(?:[/\-:.]\d{1,3}(?:st|nd|rd|th)?)+`
- Captures: "2/116", "1-2-116", "1st/2nd/3rd"
- Output format: colon-joined (e.g., "2:116:29")

### 4. Pandas 2.x Fix

Fixed index alignment issue in broadcast loop:
```python
# Before (failed on pandas 2.x)
df_out[k] = pd.Series(s_uni.values).take(codes)

# After (works on pandas 2.x)
broadcast_values = [s_uni.values[c] for c in codes]
df_out[k] = broadcast_values
```

---

## Extraction Results (10K records)

| Category | Match Rate |
|----------|-----------|
| Role_Terms | 96.6% |
| Unit_Terms | 48.8% |
| Org_Terms | 47.8% |
| Digit_Sequences | 25.8% |
| Unit+Digit pairs | 45.4% |
| Alpha+Digit pairs | 48.4% |

---

## Design Decisions

1. **Build-time glossary generation** — Run once when configs change, not at runtime. Simpler debugging, explicit artifact.

2. **Glossary excludes situational vocabulary** — Terms like "OMAHA", "DZ-O" are LLM signals, not regex targets. Glossary focuses on unit structure terms.

3. **Digit_Sequences as list** — Output is colon-joined string per match (e.g., "2:116"), collected into list per record. Consistent with other pair columns.

---

## Next Steps

1. **Component Routing** — Use extraction signals to route records to components
2. **Batching** — Group records for efficient LLM processing
3. **Zero-Shot Strategy** — Baseline consolidation approach

---

## Commands Used

```bash
# Generate glossary
python3.11 -m src.preprocessing.glossary_generator

# Run preprocessing
python3.11 -m src.preprocessing.preprocessing_adapter --timing

# Verify output
python3.11 -c "import pandas as pd; df = pd.read_parquet('data/synthetic/canonical.parquet'); print(df.columns.tolist())"
```
