# Code Activity Log: 2026-01-16

**Session:** Claude Code (Opus 4.5)
**Focus:** Dual-run stateful extraction implementation (ADR-002)

---

## Summary

Implemented the dual-run stateful extraction workflow for resolver generation. This addresses timeout issues from the previous session by adding retry logic, and implements the ADR-002 decision to use dual-run extraction with hard case reconciliation to balance contextual disambiguation against drift risk.

---

## Files Created

| File | Purpose |
|------|---------|
| `src/utils/llm/token_batcher.py` | Global token-budget batching utility with soldier coherence |
| `src/strategies/resolver/generator/dual_run.py` | Dual-run orchestrator for forward + inverted extraction |
| `src/strategies/resolver/generator/reconciliation.py` | Reconciliation module for pattern validation |
| `.project_history/extracts/raw/2026-01-16_codex_dual-run-implementation.md` | Thread extract |
| `.project_history/extracts/daily/2026-01-16_resolver-dual-run-architecture.md` | Daily reconciliation |

## Files Modified

| File | Changes |
|------|---------|
| `docs/architecture/decisions/ADR-002_llm-batching-statefulness.md` | Status â†’ accepted, added dual-run decision |
| `docs/components/batching/CURRENT.md` | Added token-budget batching design, marked complete |
| `docs/components/strategies/resolver/CURRENT.md` | Added dual-run architecture section, updated status |
| `src/utils/llm/__init__.py` | Exported RetryConfig, token batching classes |
| `src/utils/llm/base.py` | Added RetryConfig, retry methods with exponential backoff |
| `src/strategies/resolver/generator/prompts.py` | Added HARD_CASE_INSTRUCTIONS, updated prompts |
| `src/strategies/resolver/generator/generate.py` | Integrated dual-run workflow, added CLI flags |

---

## New Components Implemented

### 1. Token Budget Batcher (`src/utils/llm/token_batcher.py`)

Global utility for token-based batching with soldier coherence.

```python
@dataclass
class TokenBatchConfig:
    token_budget: int = 8000
    estimation_method: Literal["chars", "tiktoken"] = "chars"
    chars_per_token: int = 4

class TokenBatcher:
    def create_batches(self, df, soldier_id_col, text_col, order="forward") -> List[TokenBatch]
```

Key features:
- Soldier coherence (all records for soldier in same batch)
- Greedy bin packing by token estimate
- Support for forward, inverted, and custom ordering

### 2. Retry Logic (`src/utils/llm/base.py`)

Added retry with exponential backoff for transient errors.

```python
@dataclass
class RetryConfig:
    max_retries: int = 3
    initial_delay: float = 1.0
    max_delay: float = 60.0
    exponential_base: float = 2.0
    retry_on_timeout: bool = True
    retry_on_rate_limit: bool = True
```

### 3. Dual-Run Orchestrator (`src/strategies/resolver/generator/dual_run.py`)

Orchestrates dual-run extraction per ADR-002.

```python
@dataclass
class DualRunResult:
    forward_result: RunResult
    inverted_result: RunResult

    @property
    def hard_case_agreement(self) -> Dict[str, str]:
        # Returns soldier_id -> "both" | "forward_only" | "inverted_only"

def run_dual_extraction(component_id, records_df, llm, extraction_fn, phase, token_budget) -> DualRunResult
```

### 4. Reconciliation (`src/strategies/resolver/generator/reconciliation.py`)

Reconciles dual-run results and validates against hard cases.

```python
@dataclass
class PatternComparison:
    pattern: str
    in_forward: bool
    in_inverted: bool
    status: Literal["robust", "validated", "order_dependent", "rejected"]

@dataclass
class ReconciliationResult:
    robust_patterns: List[PatternComparison]
    validated_patterns: List[PatternComparison]
    order_dependent_patterns: List[PatternComparison]
    rejected_patterns: List[PatternComparison]

    @property
    def final_patterns(self) -> List[Dict[str, Any]]

class Reconciler:
    def reconcile(self, dual_run_result, records_df, component_name) -> ReconciliationResult
```

### 5. Hard Case Flagging (prompts.py)

Added shared instruction block for all extraction phases:

```python
HARD_CASE_INSTRUCTIONS = """
HARD CASE FLAGGING:
Flag a soldier as a "hard case" if:
- Multiple component indicators present (conflicting signals)
- Key identifiers missing or ambiguous
- Unusual notation that doesn't match known patterns
- Assignment uncertain despite having records
- Transfer indicators present
"""
```

### 6. Main Orchestrator Integration (generate.py)

Added GenerationConfig and CLI flags:

```python
@dataclass
class GenerationConfig:
    use_dual_run: bool = True
    token_budget: int = 8000
    checkpoint_dir: Optional[Path] = None

# CLI flags
--no-dual-run     # Disable dual-run (use legacy single-pass)
--token-budget N  # Token budget per LLM batch (default: 8000)
```

---

## Key Decisions

1. **Token-budget batching is a global utility** - needed across all LLM phases, not just resolver
2. **Dual-run with hard case reconciliation** - balances contextual disambiguation against drift risk
3. **Hard cases as validation corpus** - LLM-flagged difficult cases become the test set for pattern validation
4. **Pattern robustness classification** - robust (both runs) / validated / order-dependent / rejected

---

## ADR-002 Status Change

Changed from "proposed" to "accepted" with Decision D:

> **Decision: Dual-Run Stateful with Hard Case Reconciliation**
>
> Run stateful extraction twice with inverted batch ordering. Have LLM flag "hard cases" during each pass. Reconcile results using hard cases as validation corpus.

---

## Open Items (Noted in Docs)

- `llm_phases.py` marked "Needs update" - could use token batching + return hard cases
- Vocabulary/differentiator phases currently use single-pass - could extend to dual-run
- These are enhancements, not blockers

---

## Next Steps

1. Test dual-run workflow end-to-end
2. Run resolver generation to validate timeouts are resolved
3. Consider extending dual-run to vocabulary and differentiator phases
